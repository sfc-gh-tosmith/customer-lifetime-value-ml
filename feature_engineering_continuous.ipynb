{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Feature Engineering with Snowflake Feature Store\n",
    "\n",
    "This notebook derives features from raw continuous customer data using **Snowflake Feature Store**.\n",
    "\n",
    "The Feature Store provides:\n",
    "- Centralized feature definitions and management\n",
    "- Automatic feature refresh on schedule\n",
    "- Point-in-time correct features for training\n",
    "- Feature lineage and discovery\n",
    "- Consistent features for training and inference\n",
    "\n",
    "**Prerequisites**: Run `generate_continuous_data.ipynb` first to create raw data tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import functions as F, Window\n",
    "from snowflake.ml.feature_store import (\n",
    "    FeatureStore,\n",
    "    FeatureView,\n",
    "    Entity,\n",
    "    CreationMode\n",
    ")\n",
    "\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = 'ML_DEMO'\n",
    "SCHEMA = 'PUBLIC'\n",
    "FEATURE_STORE_NAME = 'CLV_FEATURE_STORE'\n",
    "WAREHOUSE = 'ML_DEMO_WH'\n",
    "\n",
    "session.use_database(DATABASE)\n",
    "session.use_schema(SCHEMA)\n",
    "session.use_warehouse(WAREHOUSE)\n",
    "\n",
    "OBSERVATION_DATE = datetime(2024, 6, 30)\n",
    "\n",
    "print(f\"Database: {DATABASE}\")\n",
    "print(f\"Schema: {SCHEMA}\")\n",
    "print(f\"Feature Store: {FEATURE_STORE_NAME}\")\n",
    "print(f\"Warehouse: {WAREHOUSE}\")\n",
    "print(f\"Observation Date: {OBSERVATION_DATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Create or Connect to Feature Store\n",
    "\n",
    "A feature store in Snowflake is a schema that contains feature views (backed by dynamic tables or views)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=DATABASE,\n",
    "    name=FEATURE_STORE_NAME,\n",
    "    default_warehouse=WAREHOUSE,\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    ")\n",
    "\n",
    "print(f\"✓ Feature Store ready: {DATABASE}.{FEATURE_STORE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Register Entity\n",
    "\n",
    "Entities organize features by subject. Here we create a CUSTOMER entity with CUSTOMER_ID as the join key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    customer_entity = fs.get_entity(\"CUSTOMER\")\n",
    "    print(\"✓ CUSTOMER entity already exists\")\n",
    "except:\n",
    "    customer_entity = Entity(\n",
    "        name=\"CUSTOMER\",\n",
    "        join_keys=[\"CUSTOMER_ID\"],\n",
    "        desc=\"Customer entity for CLV prediction\"\n",
    "    )\n",
    "    fs.register_entity(customer_entity)\n",
    "    print(\"✓ Created CUSTOMER entity\")\n",
    "\n",
    "print(f\"  Join keys: {customer_entity.join_keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Feature View 1: RFM Features\n",
    "\n",
    "**RFM** (Recency, Frequency, Monetary) features capture customer purchase behavior:\n",
    "- **Recency**: Days since last purchase\n",
    "- **Frequency**: Total number of purchases  \n",
    "- **Monetary**: Total and average spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_TRANSACTIONS\")\n",
    "\n",
    "rfm_df = transactions_df.group_by(\"CUSTOMER_ID\").agg([\n",
    "    F.datediff(\n",
    "        \"day\",\n",
    "        F.max(\"TRANSACTION_DATE\"),\n",
    "        F.lit(OBSERVATION_DATE)\n",
    "    ).alias(\"RECENCY_DAYS\"),\n",
    "    F.count(\"TRANSACTION_ID\").alias(\"FREQUENCY\"),\n",
    "    F.sum(\"AMOUNT\").alias(\"MONETARY_TOTAL\"),\n",
    "    F.avg(\"AMOUNT\").alias(\"MONETARY_AVG\"),\n",
    "    F.min(\"TRANSACTION_DATE\").alias(\"FIRST_PURCHASE_DATE\"),\n",
    "    F.max(\"TRANSACTION_DATE\").alias(\"LAST_PURCHASE_DATE\")\n",
    "])\n",
    "\n",
    "rfm_df = rfm_df.with_column(\n",
    "    \"CUSTOMER_TENURE_DAYS\",\n",
    "    F.datediff(\"day\", F.col(\"FIRST_PURCHASE_DATE\"), F.lit(OBSERVATION_DATE))\n",
    ")\n",
    "\n",
    "print(\"RFM feature DataFrame:\")\n",
    "rfm_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_fv = FeatureView(\n",
    "    name=\"RFM_FEATURES\",\n",
    "    entities=[customer_entity],\n",
    "    feature_df=rfm_df,\n",
    "    refresh_freq=\"1 day\",\n",
    "    desc=\"Recency, Frequency, Monetary features from transaction history\"\n",
    ").attach_feature_desc({\n",
    "    \"RECENCY_DAYS\": \"Days since last purchase (lower = more recent)\",\n",
    "    \"FREQUENCY\": \"Total number of purchases (count of transactions)\",\n",
    "    \"MONETARY_TOTAL\": \"Total amount spent across all transactions\",\n",
    "    \"MONETARY_AVG\": \"Average transaction amount\",\n",
    "    \"CUSTOMER_TENURE_DAYS\": \"Days since first purchase (customer age)\"\n",
    "})\n",
    "\n",
    "rfm_fv_registered = fs.register_feature_view(\n",
    "    feature_view=rfm_fv,\n",
    "    version=\"1.0\",\n",
    "    block=True\n",
    ")\n",
    "\n",
    "print(\"✓ Registered RFM_FEATURES feature view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Feature View 2: Purchase Pattern Features\n",
    "\n",
    "Advanced behavioral features:\n",
    "- Inter-purchase time patterns\n",
    "- Product category diversity\n",
    "- Recent activity windows (30d, 90d)\n",
    "- Spending trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_CUSTOMERS_PROFILE\")\n",
    "transactions_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_TRANSACTIONS\")\n",
    "\n",
    "purchase_patterns_df = transactions_df.group_by(\"CUSTOMER_ID\").agg([\n",
    "    F.count_distinct(\"PRODUCT_CATEGORY\").alias(\"UNIQUE_CATEGORIES_PURCHASED\"),\n",
    "    F.sum(\"QUANTITY\").alias(\"TOTAL_ITEMS_PURCHASED\"),\n",
    "    F.sum(\n",
    "        F.when(\n",
    "            F.col(\"TRANSACTION_DATE\") >= F.dateadd(\"day\", F.lit(-30), F.lit(OBSERVATION_DATE)),\n",
    "            F.col(\"AMOUNT\")\n",
    "        ).otherwise(F.lit(0))\n",
    "    ).alias(\"RECENT_30D_AMOUNT\"),\n",
    "    F.sum(\n",
    "        F.when(\n",
    "            F.col(\"TRANSACTION_DATE\") >= F.dateadd(\"day\", F.lit(-30), F.lit(OBSERVATION_DATE)),\n",
    "            F.lit(1)\n",
    "        ).otherwise(F.lit(0))\n",
    "    ).alias(\"RECENT_30D_COUNT\"),\n",
    "    F.sum(\n",
    "        F.when(\n",
    "            F.col(\"TRANSACTION_DATE\") >= F.dateadd(\"day\", F.lit(-90), F.lit(OBSERVATION_DATE)),\n",
    "            F.col(\"AMOUNT\")\n",
    "        ).otherwise(F.lit(0))\n",
    "    ).alias(\"RECENT_90D_AMOUNT\"),\n",
    "    F.sum(\n",
    "        F.when(\n",
    "            F.col(\"TRANSACTION_DATE\") >= F.dateadd(\"day\", F.lit(-90), F.lit(OBSERVATION_DATE)),\n",
    "            F.lit(1)\n",
    "        ).otherwise(F.lit(0))\n",
    "    ).alias(\"RECENT_90D_COUNT\")\n",
    "])\n",
    "\n",
    "print(\"Purchase patterns feature DataFrame:\")\n",
    "purchase_patterns_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_patterns_fv = FeatureView(\n",
    "    name=\"PURCHASE_PATTERNS\",\n",
    "    entities=[customer_entity],\n",
    "    feature_df=purchase_patterns_df,\n",
    "    refresh_freq=\"1 day\",\n",
    "    desc=\"Purchase behavior patterns and trends\"\n",
    ").attach_feature_desc({\n",
    "    \"UNIQUE_CATEGORIES_PURCHASED\": \"Number of distinct product categories purchased\",\n",
    "    \"TOTAL_ITEMS_PURCHASED\": \"Total quantity of items purchased\",\n",
    "    \"RECENT_30D_AMOUNT\": \"Total spending in last 30 days\",\n",
    "    \"RECENT_30D_COUNT\": \"Number of transactions in last 30 days\",\n",
    "    \"RECENT_90D_AMOUNT\": \"Total spending in last 90 days\",\n",
    "    \"RECENT_90D_COUNT\": \"Number of transactions in last 90 days\"\n",
    "})\n",
    "\n",
    "purchase_patterns_fv_registered = fs.register_feature_view(\n",
    "    feature_view=purchase_patterns_fv,\n",
    "    version=\"1.0\",\n",
    "    block=True\n",
    ")\n",
    "\n",
    "print(\"✓ Registered PURCHASE_PATTERNS feature view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Feature View 3: Engagement Features\n",
    "\n",
    "Non-purchase engagement signals:\n",
    "- Website visits\n",
    "- Email interactions\n",
    "- Support tickets\n",
    "- Product views and cart adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_INTERACTIONS\")\n",
    "\n",
    "engagement_df = interactions_df.group_by(\"CUSTOMER_ID\").agg([\n",
    "    F.count(\"INTERACTION_ID\").alias(\"TOTAL_INTERACTIONS\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"EVENT_TYPE\") == F.lit(\"website_visit\"), F.lit(1))\n",
    "        .otherwise(F.lit(0))\n",
    "    ).alias(\"WEBSITE_VISITS\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"EVENT_TYPE\") == F.lit(\"email_open\"), F.lit(1))\n",
    "        .otherwise(F.lit(0))\n",
    "    ).alias(\"EMAIL_OPENS\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"EVENT_TYPE\") == F.lit(\"email_click\"), F.lit(1))\n",
    "        .otherwise(F.lit(0))\n",
    "    ).alias(\"EMAIL_CLICKS\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"EVENT_TYPE\") == F.lit(\"support_ticket\"), F.lit(1))\n",
    "        .otherwise(F.lit(0))\n",
    "    ).alias(\"SUPPORT_TICKETS\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"EVENT_TYPE\") == F.lit(\"product_view\"), F.lit(1))\n",
    "        .otherwise(F.lit(0))\n",
    "    ).alias(\"PRODUCT_VIEWS\"),\n",
    "    F.sum(\n",
    "        F.when(F.col(\"EVENT_TYPE\") == F.lit(\"cart_add\"), F.lit(1))\n",
    "        .otherwise(F.lit(0))\n",
    "    ).alias(\"CART_ADDS\")\n",
    "])\n",
    "\n",
    "engagement_df = engagement_df.with_column(\n",
    "    \"EMAIL_ENGAGEMENT_RATE\",\n",
    "    F.div0(F.col(\"EMAIL_CLICKS\"), F.col(\"EMAIL_OPENS\"))\n",
    ")\n",
    "\n",
    "print(\"Engagement feature DataFrame:\")\n",
    "engagement_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "engagement_fv = FeatureView(\n",
    "    name=\"ENGAGEMENT_FEATURES\",\n",
    "    entities=[customer_entity],\n",
    "    feature_df=engagement_df,\n",
    "    refresh_freq=\"1 day\",\n",
    "    desc=\"Customer engagement and interaction features\"\n",
    ").attach_feature_desc({\n",
    "    \"TOTAL_INTERACTIONS\": \"Total count of all customer interactions\",\n",
    "    \"WEBSITE_VISITS\": \"Number of website visits\",\n",
    "    \"EMAIL_OPENS\": \"Number of emails opened\",\n",
    "    \"EMAIL_CLICKS\": \"Number of email links clicked\",\n",
    "    \"SUPPORT_TICKETS\": \"Number of support tickets created\",\n",
    "    \"PRODUCT_VIEWS\": \"Number of product views\",\n",
    "    \"CART_ADDS\": \"Number of items added to cart\",\n",
    "    \"EMAIL_ENGAGEMENT_RATE\": \"Email click-through rate (clicks / opens)\"\n",
    "})\n",
    "\n",
    "engagement_fv_registered = fs.register_feature_view(\n",
    "    feature_view=engagement_fv,\n",
    "    version=\"1.0\",\n",
    "    block=True\n",
    ")\n",
    "\n",
    "print(\"✓ Registered ENGAGEMENT_FEATURES feature view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Calculate Target Variable and Add to Customer Profile\n",
    "\n",
    "**⚠️ IMPORTANT NOTE ON REAL-WORLD IMPLEMENTATION:**\n",
    "\n",
    "In this demonstration, we calculate `FUTURE_12M_LTV` using a synthetic formula based on current features. This is necessary because we're working with simulated data.\n",
    "\n",
    "**In a real-world production system, you would:**\n",
    "1. **Use actual historical data**: Calculate the target by looking back at what customers *actually* spent in the 12 months following the observation date\n",
    "2. **Example**: If observation_date = 2023-06-30, you'd sum all transactions from 2023-07-01 to 2024-06-30\n",
    "3. **SQL approach**: `SELECT customer_id, SUM(amount) as future_12m_ltv FROM transactions WHERE transaction_date BETWEEN observation_date + 1 AND observation_date + 365 GROUP BY customer_id`\n",
    "4. **This requires waiting**: You need 12 months of future data before you can train the model\n",
    "5. **For inference**: You predict for the *current* period where you don't yet know the future value\n",
    "\n",
    "**Key difference**: Real targets come from future observed behavior, not formulas. The formula here is only for demonstration purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to get RFM features to calculate the target\n",
    "# (In real-world, you'd query historical future transactions directly)\n",
    "\n",
    "transactions_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_TRANSACTIONS\")\n",
    "interactions_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_INTERACTIONS\")\n",
    "\n",
    "# Calculate basic RFM metrics needed for target calculation\n",
    "rfm_for_target = transactions_df.group_by(\"CUSTOMER_ID\").agg([\n",
    "    F.datediff(\"day\", F.max(\"TRANSACTION_DATE\"), F.lit(OBSERVATION_DATE)).alias(\"RECENCY_DAYS\"),\n",
    "    F.count(\"TRANSACTION_ID\").alias(\"FREQUENCY\"),\n",
    "    F.sum(\"AMOUNT\").alias(\"MONETARY_TOTAL\")\n",
    "])\n",
    "\n",
    "# Calculate total interactions\n",
    "interactions_count = interactions_df.group_by(\"CUSTOMER_ID\").agg(\n",
    "    F.count(\"INTERACTION_ID\").alias(\"TOTAL_INTERACTIONS\")\n",
    ")\n",
    "\n",
    "# Join RFM and interactions with customer profile\n",
    "customers_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_CUSTOMERS_PROFILE\")\n",
    "\n",
    "customers_with_metrics = customers_df.join(\n",
    "    rfm_for_target, \n",
    "    on=\"CUSTOMER_ID\", \n",
    "    how=\"left\"\n",
    ").join(\n",
    "    interactions_count,\n",
    "    on=\"CUSTOMER_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Calculate synthetic target variable (simulating what future 12 months would bring)\n",
    "# In production: This would be SUM(actual_transactions) from next 12 months\n",
    "customers_with_target = customers_with_metrics.with_column(\n",
    "    \"FUTURE_12M_LTV\",\n",
    "    (\n",
    "        F.col(\"MONETARY_TOTAL\") * F.lit(0.6) *\n",
    "        F.greatest(F.lit(0.5), (F.lit(1.5) - F.col(\"RECENCY_DAYS\") / F.lit(180))) *\n",
    "        F.least(F.lit(2.0), (F.lit(1) + F.col(\"FREQUENCY\") / F.lit(20))) *\n",
    "        (F.lit(1) + F.col(\"TOTAL_INTERACTIONS\") / F.lit(500)) *\n",
    "        F.uniform(F.lit(0.7), F.lit(1.3), F.random())\n",
    "    )\n",
    ")\n",
    "\n",
    "# Select just customer profile columns + target\n",
    "customers_profile_with_target = customers_with_target.select([\n",
    "    \"CUSTOMER_ID\",\n",
    "    \"SIGNUP_DATE\", \n",
    "    \"AGE_GROUP\",\n",
    "    \"REGION\",\n",
    "    \"SEGMENT\",\n",
    "    \"HISTORY_DAYS\",\n",
    "    \"FUTURE_12M_LTV\"\n",
    "])\n",
    "\n",
    "# Save enhanced customer profile\n",
    "customers_profile_with_target.write.mode(\"overwrite\").save_as_table(\"CONTINUOUS_CUSTOMERS_PROFILE_WITH_TARGET\")\n",
    "\n",
    "print(f\"✓ Saved customer profile with target: {customers_profile_with_target.count()} rows\")\n",
    "\n",
    "stats_df = session.table(\"CONTINUOUS_CUSTOMERS_PROFILE_WITH_TARGET\").select(\n",
    "    F.avg(\"FUTURE_12M_LTV\").alias(\"AVG_LTV\"),\n",
    "    F.median(\"FUTURE_12M_LTV\").alias(\"MEDIAN_LTV\"),\n",
    "    F.min(\"FUTURE_12M_LTV\").alias(\"MIN_LTV\"),\n",
    "    F.max(\"FUTURE_12M_LTV\").alias(\"MAX_LTV\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"  Average: ${stats_df['AVG_LTV']:.2f}\")\n",
    "print(f\"  Median:  ${stats_df['MEDIAN_LTV']:.2f}\")\n",
    "print(f\"  Min:     ${stats_df['MIN_LTV']:.2f}\")\n",
    "print(f\"  Max:     ${stats_df['MAX_LTV']:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Generate Training Dataset from Feature Store\n",
    "\n",
    "Now we use the enhanced customer profile (with target) as the spine and join all features from the Feature Store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use customer profile with target as spine\n",
    "spine_df = session.table(f\"{DATABASE}.{SCHEMA}.CONTINUOUS_CUSTOMERS_PROFILE_WITH_TARGET\")\n",
    "\n",
    "print(f\"Spine DataFrame: {spine_df.count()} customers with target variable\")\n",
    "spine_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training dataset by joining spine with all feature views\n",
    "training_df = fs.generate_training_set(\n",
    "    spine_df=spine_df,\n",
    "    features=[\n",
    "        rfm_fv_registered,\n",
    "        purchase_patterns_fv_registered,\n",
    "        engagement_fv_registered\n",
    "    ],\n",
    "    save_as=\"CONTINUOUS_TRAINING_DATA_WITH_TARGET\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training dataset created: {training_df.count()} rows\")\n",
    "print(f\"  Columns: {len(training_df.columns)}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "for col in sorted(training_df.columns):\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\n✓ Dataset includes FUTURE_12M_LTV from customer profile\")\n",
    "print(\"✓ All features have automatic lineage tracking via Feature Store\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## List All Feature Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All registered feature views:\")\n",
    "fs.list_feature_views(entity_name=\"CUSTOMER\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Feature Store Setup**: Created feature store and registered CUSTOMER entity\n",
    "2. **Feature Views**: Created 3 managed feature views:\n",
    "   - RFM_FEATURES (recency, frequency, monetary)\n",
    "   - PURCHASE_PATTERNS (behavioral patterns)\n",
    "   - ENGAGEMENT_FEATURES (non-purchase interactions)\n",
    "3. **Target Variable Creation**: Calculated FUTURE_12M_LTV and added to customer profile\n",
    "   - ⚠️ In production: Would use actual historical future transactions, not formulas\n",
    "   - Requires waiting 12 months after observation date to create training labels\n",
    "4. **Training Dataset**: Generated training data combining customer profile + all features\n",
    "5. **Benefits**:\n",
    "   - Centralized feature definitions\n",
    "   - Automatic refresh (1 day schedule)\n",
    "   - Reusable for training and inference\n",
    "   - Feature lineage and discovery\n",
    "   - Clean separation: raw data → features → training dataset\n",
    "\n",
    "**Output Tables:**\n",
    "- `CONTINUOUS_CUSTOMERS_PROFILE_WITH_TARGET`: Customer profiles with target variable\n",
    "- `CONTINUOUS_TRAINING_DATA_WITH_TARGET`: Complete training dataset (profile + features + target)\n",
    "\n",
    "**Next Steps**:\n",
    "- Use `CONTINUOUS_TRAINING_DATA_WITH_TARGET` for model training\n",
    "- Features automatically refresh daily from raw data\n",
    "- Use same feature views for inference to ensure consistency\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Continuous Prediction Customer Data\n",
    "\n",
    "This notebook generates realistic data for customers with established transaction history.\n",
    "\n",
    "**Continuous Scenario**: Customers with 3+ months of activity and rich behavioral data.\n",
    "\n",
    "We'll generate:\n",
    "- 50,000 customers\n",
    "- 500,000+ raw transactions\n",
    "- Customer interactions and engagement events\n",
    "- Then derive RFM and other features from raw data"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.snowpark import functions as F\n",
    "\n",
    "# Get active Snowflake session\n",
    "session = get_active_session()\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your database and schema here:"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database and schema configuration\n",
    "DATABASE = 'ML_DEMO'\n",
    "SCHEMA = 'PUBLIC'\n",
    "\n",
    "# Set context\n",
    "session.use_database(DATABASE)\n",
    "session.use_schema(SCHEMA)\n",
    "\n",
    "print(f\"Using database: {DATABASE}\")\n",
    "print(f\"Using schema: {SCHEMA}\")\n",
    "print(f\"Current warehouse: {session.get_current_warehouse()}\")"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Data Generation Parameters"
   ],
   "attachments": {}
  },
  {
   "cell_type": "code",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "NUM_CUSTOMERS = 50000\n",
    "OBSERVATION_DATE = datetime(2024, 6, 30)\n",
    "MIN_HISTORY_DAYS = 90\n",
    "MAX_HISTORY_DAYS = 540"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Customer Profiles"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_segments = ['high_value', 'medium_value', 'low_value', 'at_risk', 'churned']\n",
    "segment_weights = [0.15, 0.35, 0.30, 0.12, 0.08]\n",
    "\n",
    "customers = []\n",
    "\n",
    "for customer_id in range(1, NUM_CUSTOMERS + 1):\n",
    "    history_days = random.randint(MIN_HISTORY_DAYS, MAX_HISTORY_DAYS)\n",
    "    signup_date = OBSERVATION_DATE - timedelta(days=history_days)\n",
    "    \n",
    "    segment = np.random.choice(customer_segments, p=segment_weights)\n",
    "    \n",
    "    age_groups = ['18-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "    age_group = np.random.choice(age_groups, p=[0.10, 0.30, 0.27, 0.18, 0.10, 0.05])\n",
    "    \n",
    "    regions = ['Northeast', 'Southeast', 'Midwest', 'Southwest', 'West']\n",
    "    region = np.random.choice(regions)\n",
    "    \n",
    "    customers.append({\n",
    "        'CUSTOMER_ID': customer_id,\n",
    "        'SIGNUP_DATE': signup_date,\n",
    "        'AGE_GROUP': age_group,\n",
    "        'REGION': region,\n",
    "        'SEGMENT': segment,\n",
    "        'HISTORY_DAYS': history_days\n",
    "    })\n",
    "\n",
    "customers_df = pd.DataFrame(customers)\n",
    "print(f\"Generated {len(customers_df)} customer profiles\")\n",
    "customers_df.head()"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Raw Transactions\n",
    "\n",
    "**Why raw transactions**: In real-world scenarios, we don't have pre-computed features. We start with transactional data and must derive meaningful metrics."
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = []\n",
    "\n",
    "product_categories = ['electronics', 'clothing', 'home_goods', 'beauty', 'sports', 'books', 'toys', 'grocery']\n",
    "\n",
    "for _, customer in customers_df.iterrows():\n",
    "    customer_id = customer['customer_id']\n",
    "    signup_date = customer['signup_date']\n",
    "    segment = customer['segment']\n",
    "    \n",
    "    if segment == 'HIGH_VALUE':\n",
    "        num_transactions = int(np.random.uniform(20, 60))\n",
    "        avg_amount = np.random.uniform(100, 300)\n",
    "        purchase_frequency_days = 7\n",
    "    elif segment == 'MEDIUM_VALUE':\n",
    "        num_transactions = int(np.random.uniform(8, 25))\n",
    "        avg_amount = np.random.uniform(50, 120)\n",
    "        purchase_frequency_days = 15\n",
    "    elif segment == 'LOW_VALUE':\n",
    "        num_transactions = int(np.random.uniform(3, 10))\n",
    "        avg_amount = np.random.uniform(20, 60)\n",
    "        purchase_frequency_days = 30\n",
    "    elif segment == 'AT_RISK':\n",
    "        num_transactions = int(np.random.uniform(5, 15))\n",
    "        avg_amount = np.random.uniform(40, 100)\n",
    "        purchase_frequency_days = 45\n",
    "    else:\n",
    "        num_transactions = int(np.random.uniform(1, 5))\n",
    "        avg_amount = np.random.uniform(25, 70)\n",
    "        purchase_frequency_days = 60\n",
    "    \n",
    "    current_date = signup_date + timedelta(days=random.randint(0, 7))\n",
    "    \n",
    "    for txn in range(num_transactions):\n",
    "        days_since_last = int(np.random.exponential(purchase_frequency_days))\n",
    "        current_date = current_date + timedelta(days=max(1, days_since_last))\n",
    "        \n",
    "        if current_date > OBSERVATION_DATE:\n",
    "            break\n",
    "        \n",
    "        amount = max(5, np.random.gamma(shape=2, scale=avg_amount/2))\n",
    "        amount = round(amount, 2)\n",
    "        \n",
    "        category = np.random.choice(product_categories)\n",
    "        quantity = int(np.random.poisson(lam=2) + 1)\n",
    "        \n",
    "        transactions.append({\n",
    "            'TRANSACTION_ID': len(transactions) + 1,\n",
    "            'CUSTOMER_ID': customer_id,\n",
    "            'TRANSACTION_DATE': current_date,\n",
    "            'AMOUNT': amount,\n",
    "            'PRODUCT_CATEGORY': category,\n",
    "            'QUANTITY': quantity\n",
    "        })\n",
    "\n",
    "transactions_df = pd.DataFrame(transactions)\n",
    "print(f\"Generated {len(transactions_df)} transactions\")\n",
    "transactions_df.head(10)"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Customer Interaction Events"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = []\n",
    "event_types = ['website_visit', 'email_open', 'email_click', 'support_ticket', 'product_view', 'cart_add']\n",
    "\n",
    "for _, customer in customers_df.iterrows():\n",
    "    customer_id = customer['customer_id']\n",
    "    signup_date = customer['signup_date']\n",
    "    segment = customer['segment']\n",
    "    \n",
    "    if segment == 'HIGH_VALUE':\n",
    "        num_interactions = int(np.random.uniform(100, 300))\n",
    "    elif segment == 'MEDIUM_VALUE':\n",
    "        num_interactions = int(np.random.uniform(50, 120))\n",
    "    elif segment == 'LOW_VALUE':\n",
    "        num_interactions = int(np.random.uniform(20, 60))\n",
    "    elif segment == 'AT_RISK':\n",
    "        num_interactions = int(np.random.uniform(15, 50))\n",
    "    else:\n",
    "        num_interactions = int(np.random.uniform(5, 20))\n",
    "    \n",
    "    for _ in range(num_interactions):\n",
    "        days_offset = random.randint(0, customer['history_days'])\n",
    "        event_date = signup_date + timedelta(days=days_offset)\n",
    "        \n",
    "        if event_date > OBSERVATION_DATE:\n",
    "            continue\n",
    "        \n",
    "        event_type = np.random.choice(event_types, p=[0.35, 0.20, 0.10, 0.05, 0.20, 0.10])\n",
    "        \n",
    "        interactions.append({\n",
    "            'INTERACTION_ID': len(interactions) + 1,\n",
    "            'CUSTOMER_ID': customer_id,\n",
    "            'EVENT_DATE': event_date,\n",
    "            'EVENT_TYPE': event_type\n",
    "        })\n",
    "\n",
    "interactions_df = pd.DataFrame(interactions)\n",
    "print(f\"Generated {len(interactions_df)} customer interactions\")\n",
    "interactions_df.head(10)"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive RFM Features from Raw Transactions\n",
    "\n",
    "**RFM Metrics Explained**:\n",
    "- **Recency**: Days since last purchase - Recent customers are more likely to purchase again\n",
    "- **Frequency**: Number of purchases - Frequent buyers show loyalty and habit\n",
    "- **Monetary**: Total/average spend - High spenders have higher lifetime value potential\n",
    "\n",
    "These three metrics are fundamental because they capture:\n",
    "1. Current engagement (Recency)\n",
    "2. Behavioral patterns (Frequency)\n",
    "3. Economic value (Monetary)"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_features = transactions_df.groupby('customer_id').agg(\n",
    "    recency_days=('transaction_date', lambda x: (OBSERVATION_DATE - x.max()).days),\n",
    "    frequency=('transaction_id', 'count'),\n",
    "    monetary_total=('amount', 'sum'),\n",
    "    monetary_avg=('amount', 'mean'),\n",
    "    first_purchase_date=('transaction_date', 'min'),\n",
    "    last_purchase_date=('transaction_date', 'max')\n",
    ").reset_index()\n",
    "\n",
    "rfm_features['customer_tenure_days'] = (OBSERVATION_DATE - rfm_features['first_purchase_date']).dt.days\n",
    "\n",
    "print(\"RFM Features derived from raw transactions:\")\n",
    "rfm_features.head(10)"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Purchase Pattern Features\n",
    "\n",
    "**Why these matter**:\n",
    "- **Inter-purchase time**: Identifies purchase rhythm and consistency\n",
    "- **Product diversity**: Customers who buy across categories tend to have higher engagement\n",
    "- **Average order value**: Indicates spending capacity per transaction\n",
    "- **Trend indicators**: Growing vs declining purchase patterns predict future behavior"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_patterns = []\n",
    "\n",
    "for customer_id in customers_df['customer_id']:\n",
    "    cust_txns = transactions_df[transactions_df['customer_id'] == customer_id].sort_values('transaction_date')\n",
    "    \n",
    "    if len(cust_txns) > 1:\n",
    "        dates = pd.to_datetime(cust_txns['transaction_date'])\n",
    "        inter_purchase_times = dates.diff().dt.days.dropna()\n",
    "        avg_inter_purchase_days = inter_purchase_times.mean() if len(inter_purchase_times) > 0 else None\n",
    "        std_inter_purchase_days = inter_purchase_times.std() if len(inter_purchase_times) > 0 else None\n",
    "    else:\n",
    "        avg_inter_purchase_days = None\n",
    "        std_inter_purchase_days = None\n",
    "    \n",
    "    unique_categories = cust_txns['product_category'].nunique()\n",
    "    total_quantity = cust_txns['quantity'].sum()\n",
    "    \n",
    "    recent_30d_txns = cust_txns[cust_txns['transaction_date'] >= (OBSERVATION_DATE - timedelta(days=30))]\n",
    "    recent_30d_amount = recent_30d_txns['amount'].sum()\n",
    "    recent_30d_count = len(recent_30d_txns)\n",
    "    \n",
    "    recent_90d_txns = cust_txns[cust_txns['transaction_date'] >= (OBSERVATION_DATE - timedelta(days=90))]\n",
    "    recent_90d_amount = recent_90d_txns['amount'].sum()\n",
    "    recent_90d_count = len(recent_90d_txns)\n",
    "    \n",
    "    if len(cust_txns) >= 4:\n",
    "        mid_point = len(cust_txns) // 2\n",
    "        first_half_avg = cust_txns.iloc[:mid_point]['amount'].mean()\n",
    "        second_half_avg = cust_txns.iloc[mid_point:]['amount'].mean()\n",
    "        spending_trend = (second_half_avg - first_half_avg) / first_half_avg if first_half_avg > 0 else 0\n",
    "    else:\n",
    "        spending_trend = 0\n",
    "    \n",
    "    purchase_patterns.append({\n",
    "        'CUSTOMER_ID': customer_id,\n",
    "        'AVG_INTER_PURCHASE_DAYS': avg_inter_purchase_days,\n",
    "        'STD_INTER_PURCHASE_DAYS': std_inter_purchase_days,\n",
    "        'UNIQUE_CATEGORIES_PURCHASED': unique_categories,\n",
    "        'TOTAL_ITEMS_PURCHASED': total_quantity,\n",
    "        'recent_30d_amount': recent_30d_amount,\n",
    "        'recent_30d_count': recent_30d_count,\n",
    "        'recent_90d_amount': recent_90d_amount,\n",
    "        'recent_90d_count': recent_90d_count,\n",
    "        'SPENDING_TREND': spending_trend\n",
    "    })\n",
    "\n",
    "purchase_patterns_df = pd.DataFrame(purchase_patterns)\n",
    "print(\"Purchase pattern features:\")\n",
    "purchase_patterns_df.head(10)"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive Engagement Features from Interactions\n",
    "\n",
    "**Why these matter**: Engagement beyond purchases indicates interest and intent. High engagement without recent purchases may signal opportunity or friction."
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engagement_features = interactions_df.groupby('customer_id').agg(\n",
    "    total_interactions=('interaction_id', 'count'),\n",
    "    website_visits=('event_type', lambda x: (x == 'website_visit').sum()),\n",
    "    email_opens=('event_type', lambda x: (x == 'email_open').sum()),\n",
    "    email_clicks=('event_type', lambda x: (x == 'email_click').sum()),\n",
    "    support_tickets=('event_type', lambda x: (x == 'support_ticket').sum()),\n",
    "    product_views=('event_type', lambda x: (x == 'product_view').sum()),\n",
    "    cart_adds=('event_type', lambda x: (x == 'cart_add').sum())\n",
    ").reset_index()\n",
    "\n",
    "engagement_features['email_engagement_rate'] = (\n",
    "    engagement_features['email_clicks'] / engagement_features['email_opens'].replace(0, np.nan)\n",
    ").fillna(0)\n",
    "\n",
    "print(\"Engagement features derived from interactions:\")\n",
    "engagement_features.head(10)"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Features into Final Dataset"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = customers_df.merge(rfm_features, on='customer_id', how='left')\n",
    "final_df = final_df.merge(purchase_patterns_df, on='customer_id', how='left')\n",
    "final_df = final_df.merge(engagement_features, on='customer_id', how='left')\n",
    "\n",
    "final_df.fillna(0, inplace=True)\n",
    "\n",
    "print(f\"Final dataset shape: {final_df.shape}\")\n",
    "final_df.head()"
   ],
   "id": "cell-19"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Target Variable: Forward-Looking 12-Month CLV\n",
    "\n",
    "**Why this is the label**: We predict future value, not historical. The model learns patterns that indicate future spending behavior."
   ],
   "id": "cell-20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_future_ltv(row):\n",
    "    base_ltv = row['monetary_total'] * 0.6\n",
    "    \n",
    "    recency_factor = max(0.5, 1.5 - (row['recency_days'] / 180))\n",
    "    frequency_factor = min(2.0, 1 + (row['frequency'] / 20))\n",
    "    \n",
    "    engagement_factor = 1 + (row['total_interactions'] / 500)\n",
    "    \n",
    "    trend_factor = 1 + row['spending_trend']\n",
    "    trend_factor = max(0.5, min(2.0, trend_factor))\n",
    "    \n",
    "    future_ltv = base_ltv * recency_factor * frequency_factor * engagement_factor * trend_factor\n",
    "    \n",
    "    future_ltv = future_ltv * np.random.uniform(0.7, 1.3)\n",
    "    \n",
    "    return round(max(0, future_ltv), 2)\n",
    "\n",
    "final_df['future_12m_ltv'] = final_df.apply(calculate_future_ltv, axis=1)\n",
    "\n",
    "print(f\"Average future 12-month LTV: ${final_df['future_12m_ltv'].mean():.2f}\")\n",
    "print(f\"Median future 12-month LTV: ${final_df['future_12m_ltv'].median():.2f}\")"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save All Datasets to Snowflake"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save customers profile\n",
    "customers_sf_df = session.create_dataframe(customers_df)\n",
    "customers_sf_df.write.mode('overwrite').save_as_table('CONTINUOUS_CUSTOMERS_PROFILE')\n",
    "print(f\"\u2713 Saved CONTINUOUS_CUSTOMERS_PROFILE: {customers_sf_df.count()} rows\")\n",
    "\n",
    "# Save transactions\n",
    "transactions_sf_df = session.create_dataframe(transactions_df)\n",
    "transactions_sf_df.write.mode('overwrite').save_as_table('CONTINUOUS_TRANSACTIONS')\n",
    "print(f\"\u2713 Saved CONTINUOUS_TRANSACTIONS: {transactions_sf_df.count()} rows\")\n",
    "\n",
    "# Save interactions\n",
    "interactions_sf_df = session.create_dataframe(interactions_df)\n",
    "interactions_sf_df.write.mode('overwrite').save_as_table('CONTINUOUS_INTERACTIONS')\n",
    "print(f\"\u2713 Saved CONTINUOUS_INTERACTIONS: {interactions_sf_df.count()} rows\")\n",
    "\n",
    "# Save final feature dataset\n",
    "features_sf_df = session.create_dataframe(final_df)\n",
    "features_sf_df.write.mode('overwrite').save_as_table('CONTINUOUS_CUSTOMERS_FEATURES')\n",
    "print(f\"\u2713 Saved CONTINUOUS_CUSTOMERS_FEATURES: {features_sf_df.count()} rows\")\n",
    "\n",
    "print(f\"\\n\u2713 All datasets saved to {DATABASE}.{SCHEMA}\")"
   ],
   "id": "cell-23"
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Verify Tables in Snowflake"
   ],
   "attachments": {}
  },
  {
   "cell_type": "code",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "# Show table information\n",
    "tables = session.sql(f\"\"\"\n",
    "    SELECT table_name, row_count \n",
    "    FROM {DATABASE}.INFORMATION_SCHEMA.TABLES \n",
    "    WHERE table_schema = '{SCHEMA}' \n",
    "    AND table_name LIKE 'CONTINUOUS%'\n",
    "    ORDER BY table_name\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "print(\"\\nCreated tables:\")\n",
    "print(tables)\n",
    "\n",
    "# Display sample from features table\n",
    "print(\"\\nSample data from CONTINUOUS_CUSTOMERS_FEATURES:\")\n",
    "session.table('CONTINUOUS_CUSTOMERS_FEATURES').limit(10).show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save All Datasets"
   ],
   "id": "cell-26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df.to_csv('continuous_customers_profile.csv', index=False)\n",
    "transactions_df.to_csv('continuous_transactions.csv', index=False)\n",
    "interactions_df.to_csv('continuous_interactions.csv', index=False)\n",
    "final_df.to_csv('continuous_customers_features.csv', index=False)\n",
    "\n",
    "print(\"Saved all datasets:\")\n",
    "print(\"  - continuous_customers_profile.csv\")\n",
    "print(\"  - continuous_transactions.csv\")\n",
    "print(\"  - continuous_interactions.csv\")\n",
    "print(\"  - continuous_customers_features.csv\")"
   ],
   "id": "cell-27"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Raw data generation** - Starting with transactional reality\n",
    "2. **Feature derivation** - Computing RFM and behavioral metrics from raw data\n",
    "3. **Feature engineering rationale** - Explaining why each feature matters for CLV prediction\n",
    "\n",
    "The resulting dataset is ready for model training with rich, realistic features derived from transactional patterns."
   ],
   "id": "cell-28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}